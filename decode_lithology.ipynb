{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import psycopg2\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process \n",
    "import math\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import acos, cos, asin, sin, atan2, tan, radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_lithology_file='./thesaurus_cleanup.csv'\n",
    "litho_dic_file='./litho_dico_test.csv'\n",
    "\n",
    "lithology_file='./test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Pre-processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_dic_list=[]\n",
    "def clean_up():\n",
    "    cur = pd.read_csv(cleanup_lithology_file,encoding = \"ISO-8859-1\", dtype='object')\n",
    "    cur=cur.values.tolist() \n",
    "    for record in cur:\n",
    "        cleanup_dic_list.append(record)\n",
    "def clean_text(text):\n",
    "    text=text.lower()\n",
    "    text=(re.sub('\\(.*\\)', '', text)) # removes text in parentheses\n",
    "    text=(re.sub('\\[.*\\]', '', text)) # removes text in parentheses\n",
    "    text=(re.sub('\\{.*\\}', '', text)) # removes text in parentheses\n",
    "    text=text.replace('>',' ').replace('?',' ').replace('/',' ') # removes >, ?, and /\n",
    "    text = text.replace('<',' ').replace('\\\\',' ')\n",
    "    text = text.replace('.',' ').replace(',',' ').replace(';',' ').replace(':',' ')\n",
    "    text = text.replace('%',' ').replace('-',' ').replace('_',' ')\n",
    "    text = text.replace('$', ' ').replace('@',' ').replace('~',' ').replace('^',' ')\n",
    "    text = text.replace('!',' ').replace('#',' ').replace('*',' ').replace('=',' ')\n",
    "    text = text.replace('\"',' ').replace('|',' ').replace('*',' ').replace('=',' ')\n",
    "    text = text.replace('\\n',' ').replace('\\r',' ').replace('\\t',' ')\n",
    "    #if text.isnumeric(): # if the text is number\n",
    "    #    text = re.sub('\\d', ' ', text) #replace numbers\n",
    "    text=(re.sub(r'[0-9]+', '', text)) # removes numbers\n",
    "    text = text.split('with', 1)[0]  #参数[n]表示选择结果列表中的第n个(0是第一个)片\n",
    "    text = text.split('w/', 1)[0]\n",
    "    text = text.split('/w', 1)[0]\n",
    "    text = text.split(' in ', 1)[0] #vein #ferruginous #actinolite #alkaline #cainzoic #fine #dominant\n",
    "    #text = text.split(' and ', 1)[0] #banded #andesite #sand #sandstone\n",
    "    text = text.split('within', 1)[0]\n",
    "    text = text.split('+', 1)[0]\n",
    "    text = text.split('&', 1)[0]\n",
    "    text = text.split('adjacent to', 1)[0]\n",
    "    text = text.split('poss', 1)[0]\n",
    "    text = text.split('possibly', 1)[0]\n",
    "    text = text.split('prob', 1)[0]\n",
    "    text = text.split('probable', 1)[0]\n",
    "    text = text.split('probably', 1)[0]\n",
    "    text = text.split('back to', 1)[0]\n",
    "    text = text.split('due to', 1)[0]\n",
    "    text = text.split('look', 1)[0]\n",
    "    text = text.split('looks', 1)[0]\n",
    "    text = text.split('maybe', 1)[0]\n",
    "    text = text.split('same', 1)[0]\n",
    "    text = text.split('similar', 1)[0]\n",
    "    text = text.split('slowly changing', 1)[0]\n",
    "    text = text.split('changed', 1)[0]\n",
    "    text = text.split('slowly', 1)[0]\n",
    "    text = text.split('like', 1)[0]\n",
    "\n",
    "    for cleanup_dic_ele in cleanup_dic_list:\n",
    "        cleaned_item =str(cleanup_dic_ele).replace('(','').replace(')','').replace(',','').replace('\\'','')\n",
    "        #print (cleaned_item)\n",
    "        #cleaned_item =str(cleanup_dic_ele)\n",
    "        text = text.replace(cleaned_item,'')\n",
    "    return text\n",
    "\n",
    "def tokenize(text, min_len=1):\n",
    "    '''Function that tokenize a set of strings\n",
    "    Input:\n",
    "        -text: set of strings\n",
    "        -min_len: tokens length\n",
    "    Output:\n",
    "        -list containing set of tokens'''\n",
    "\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text)\n",
    "              for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if token.isalpha() and len(token) >= min_len:\n",
    "            filtered_tokens.append(token)\n",
    "\n",
    "    return [x.lower() for x in filtered_tokens if x not in stop]\n",
    "\n",
    "\n",
    "def tokenize_and_lemma(text, min_len=0):\n",
    "    '''Function that retrieves lemmatised tokens\n",
    "    Inputs:\n",
    "        -text: set of strings\n",
    "        -min_len: length of text\n",
    "    Outputs:\n",
    "        -list containing lemmatised tokens'''\n",
    "    filtered_tokens = tokenize(text, min_len=min_len)\n",
    "\n",
    "    lemmas = [lemma.lemmatize(t) for t in filtered_tokens]\n",
    "    return lemmas\n",
    "\n",
    "litho_dico=[]\n",
    "def litho_dic():\n",
    "    cur=pd.read_csv(litho_dic_file,encoding = \"ISO-8859-1\", dtype='object')\n",
    "    cur=cur.values.tolist() \n",
    "    for record in cur:\n",
    "        litho_dico.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attributecolumn, attributevalue, \n",
    "#colllarid, from, to, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comments_dic=[]\n",
    "def Comments_Dic():\n",
    "    cur=pd.read_csv(lithology_file,encoding = \"ISO-8859-1\", dtype='object')\n",
    "    cur=cur.values.tolist() \n",
    "    for record in cur:\n",
    "        Comments_dic.append(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comments_fuzzy=[]\n",
    "def Comments_With_fuzzy():\n",
    "    bestmatch=-1\n",
    "    bestlitho=''\n",
    "    top=[]\n",
    "    i=0\n",
    "    comments_sub_list=[]\n",
    "    fieldnames=['Collar ID', 'FROM', 'TO', 'DESCRIPTION','DESCRIPTION_CLEAN','LITHOLOGY','FUZZY_SCORE']\n",
    "    out= open(\"lithology_fuzzy.csv\", \"w\",encoding =\"utf-8\")\n",
    "    for ele in fieldnames:\n",
    "        out.write('%s,' %ele)\n",
    "    out.write('\\n')\n",
    "    Comments_Dic_new = [list(elem) for elem in Comments_dic]\n",
    "    for Comments_Dic_ele in Comments_Dic_new:\n",
    "        cleaned_text=clean_text(Comments_Dic_ele[3])\n",
    "        \n",
    "        words=(re.sub('\\(.*\\)', '', cleaned_text)).strip() \n",
    "        words=words.rstrip('\\n\\r').split(\" \")\n",
    "        last=len(words)-1 #position of last word in phrase\n",
    "        \n",
    "        for litho_dico_ele in litho_dico:\n",
    "            litho_words=str(litho_dico_ele).lower().rstrip('\\n\\r').replace('(','').replace(')','').replace('\\'','').replace(',','').split(\" \")\n",
    "\n",
    "            scores=process.extract(cleaned_text, litho_words, scorer=fuzz.token_set_ratio)#fuzz.token_set_ratio/fuzz.partial_ratio/  # Matching\n",
    "            for sc in scores:                        \n",
    "                if(sc[1]>bestmatch): #better than previous best match\n",
    "                    bestmatch =  sc[1]\n",
    "                    bestlitho=litho_words[0]\n",
    "                    top.append([sc[0],sc[1]])\n",
    "                    if(sc[0]==words[last]): #bonus for being last word in phrase\n",
    "                        bestmatch=bestmatch*1.01\n",
    "                elif (sc[1]==bestmatch): #equal to previous best match\n",
    "                    if(sc[0]==words[last]): #bonus for being last word in phrase\n",
    "                        bestlitho=litho_words[0]\n",
    "                        bestmatch=bestmatch*1.01\n",
    "                    else:\n",
    "                        top.append([sc[0],sc[1]])\n",
    "\n",
    "        i=0\n",
    "        if bestmatch >80:\n",
    "            #Comments_fuzzy.append([Comments_Dic_ele[0],Comments_Dic_ele[1],cleaned_text,bestlitho,bestmatch]) #top_new[1]])  or top[0][1]\n",
    "            out.write('%s,' %Comments_Dic_ele[0].replace('(','').replace(')','').replace('\\'','').replace(',','').replace(',' , '').replace('\\n',''))\n",
    "            out.write('%s,' %Comments_Dic_ele[1])\n",
    "            out.write('%s,' %Comments_Dic_ele[2])\n",
    "            out.write('%s,' %Comments_Dic_ele[3].replace('(','').replace(')','').replace('\\'','').replace(',','').replace('\\n',''))\n",
    "            out.write('%s,' %cleaned_text)   #.replace('(','').replace(')','').replace('\\'','').replace(',','').replace('\\n',''))\n",
    "            out.write('%s,' %bestlitho.replace('(','').replace(')','').replace('[','').replace(']','').replace('\\'','').replace(',','').replace('\\n',''))\n",
    "            out.write('%d,' %bestmatch)\n",
    "            out.write('\\n')\n",
    "            top.clear()\n",
    "            CET_Litho=''\n",
    "            bestmatch=-1\n",
    "            bestlitho=''\n",
    "        else:\n",
    "            #Comments_fuzzy.append([Comments_Dic_ele[0],Comments_Dic_ele[1],cleaned_text,'Other',bestmatch])  #top_new[1]])\n",
    "            out.write('%s,' %Comments_Dic_ele[0].replace('(','').replace(')','').replace('\\'','').replace(',','').replace(',' , '').replace('\\n',''))\n",
    "            out.write('%s,' %Comments_Dic_ele[1])\n",
    "            out.write('%s,' %Comments_Dic_ele[2])\n",
    "            out.write('%s,' %Comments_Dic_ele[3].replace('(','').replace(')','').replace('\\'','').replace(',','').replace('\\n',''))\n",
    "            out.write('%s,' %cleaned_text)   #.replace('(','').replace(')','').replace('\\'','').replace(',','').replace('\\n',''))\n",
    "            out.write('Other,')\n",
    "            out.write('%d,' %bestmatch)\n",
    "            out.write('\\n')\n",
    "            top.clear()\n",
    "            CET_Litho=''\n",
    "            bestmatch=-1\n",
    "            bestlitho=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "litho_dic()\n",
    "clean_up()\n",
    "Comments_Dic()\n",
    "Comments_With_fuzzy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
